---
---

@inproceedings{naik2022bowie,
  author="Naik, Nandita Shankar and Naiman, Tiffany",
  title="'You Know, I'll Be Free': Gnosticism, Feminism, and Creativity in David Bowie's 'Blackstar' Album",
  booktitle="International Association for the Study of Popular Music Conference, 2022",
  month = may,
  year="2022",
  abbr={IASPM},
  slides={bowie_iaspm_slides.pdf},
  bibtex_show={true},
  pdf={naik_iaspm_paper.pdf},
  abstract="David Bowie released his final album, Blackstar (2016), two days before passing away from liver cancer. The two music videos released with the album, “Blackstar” and “Lazarus,” show Bowie grappling with ideas of death and mortality, and have characters that reoccur across both the videos, some played by Bowie. This paper proposes a way to read these videos through the lens of Gnosticism, a mystical offshoot of Christianity. I argue that these stories reference the Gnostic creation myth of the Fall and interpret a recurring female figure within the videos as Sophia, the Gnostic mother figure. To do this, I analyze The Secret Book of John, which details the Gnostic creation myth, as well as Whitehead’s process philosophy and feminist philosophy of religion.
The Gnostics believed that there exist two worlds, our world and a perfect world where God existed, and that if a person attained gnosis, a knowledge of this other world, then they would be able to escape to this perfect world upon death. I argue that a character played by Bowie in the “Lazarus” video, who is depicted as writing and creating, achieves gnosis. In these videos, creativity serves as a method of gaining a deeper self-knowledge--or gnosis--that would lead to transcendence. This analysis might also serve to elucidate Bowie’s own process in creating the Blackstar album, suggesting that creativity can be a way to search for spiritual meaning and reckon with one’s own mortality.",
}

@inproceedings{naik2023contextvqa,
    title = {{Context-VQA}: Towards Context-Aware and Purposeful {Visual} {Question} {Answering}},
    author = "Nandita Naik and Christopher Potts and Elisa Kreiss",
    booktitle = "2023",
    month = oct,
    year = "2023",
    address = "Paris, France",
    booktitle = "ICCV: 5th Workshop on Closing the Loop Between Vision and Language",
    abbr={ICCV CLVL},
    bibtex_show={true},
    selected={true},
    html = {https://arxiv.org/abs/2307.15745},
    pdf={https://openaccess.thecvf.com/content/ICCV2023W/CLVL/papers/Naik_Context-VQA_Towards_Context-Aware_and_Purposeful_Visual_Question_Answering_ICCVW_2023_paper.pdf},
    abstract = "Visual question answering (VQA) has the potential to make the Internet more accessible in an interactive way, allowing people who cannot see images to ask questions about them. However, multiple studies have shown that people who are blind or have low-vision prefer image explanations that incorporate the context in which an image appears, yet current VQA datasets focus on images in isolation. We argue that VQA models will not fully succeed at meeting people's needs unless they take context into account. To further motivate and analyze the distinction between different contexts, we introduce Context-VQA, a VQA dataset that pairs images with contexts, specifically types of websites (e.g., a shopping website). We find that the types of questions vary systematically across contexts. For example, images presented in a travel context garner 2 times more 'Where?' questions, and images on social media and news garner 2.8 and 1.8 times more 'Who?' questions than the average. We also find that context effects are especially important when participants can't see the image. These results demonstrate that context affects the types of questions asked and that VQA models should be context-sensitive to better meet people's needs, especially in accessibility settings."
}

@misc{naik2024commvqa,
      title={CommVQA: Situating Visual Question Answering Within Communicative Contexts}, 
      author={Nandita Naik and Christopher Potts and Elisa Kreiss},
      year={2024},
      eprint={2402.15002},
      arxiv={2402.15002},
      selected={true},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      abbr={Preprint},
      bibtex_show={true},
      pdf={https://arxiv.org/pdf/2402.15002.pdf},
      abstract = "Current visual question answering (VQA) models tend to be trained and evaluated on image-question pairs in isolation. However, the questions people ask are dependent on their informational needs and prior knowledge about the image content. To evaluate how situating images within naturalistic contexts shapes visual questions, we introduce CommVQA, a VQA dataset consisting of images, image descriptions, real-world communicative scenarios where the image might appear (e.g., a travel website), and follow-up questions and answers conditioned on the scenario. We show that CommVQA poses a challenge for current models. Providing contextual information to VQA models improves performance broadly, highlighting the relevance of situating systems within a communicative scenario."
}